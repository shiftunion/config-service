# Integrate learning with reflection

## Code Repo
https://github.com/shiftunion/config-service
State: Builds, works OK, unit test pass, E2E a bit flakey

## 1. What surprised you?
- I had way too much of fun here. 
- I haven't coded frequently for over five years, and I don't know Python! This was liberating
- I felt years of frustration at my atrophying language skills, lift and dissipate, as we can focus on the core higher level concepts, which have always been more interesting to me.
    - Marvelled at how easy it was to drill down and use the agent to understand and modify code.
- Shocked at just how far these tools have come, since I tried them 6 months ago
- Surprised at how easy it was to get something up and running, to iterate many times, and how the context could be switched between different coding assistance very easily (Codex, Chat-GPT, Cline, Co-pilot).

## 2. What frustrated you?
The agents seem to have no concept of variable confidence? They always seem confident, even when it does things that are not right. 
- I wish it could say, I don't know, but try this...
- I've implemented this pull-request, but my confidence is low, maybe try another model :)

## 3. How would you rate your planning efforts?
My planning efforts were... okay. I love the meta-prompting approach, and getting multiple agents to critique each other, highlighting gaps and opportunities.
I feel like I facilitated them well in and agentic brainstorming workshop! No ego's... except mine!

## 4. Did you experience any overwhelm?
- I felt a little overwhelm when I fell into old habits of spending too long in front of the keyboard (troubleshooting build and config), where I know I should have take a break and get some perspective! It's hard to break old habits about reading code, when my first point of call should be to the agent.
- I don’t know Python, which I think was an interesting aspect of this exercise for me, where I had to trust the agent, and focus on architectural and design fundamentals…
- I got stuck in some interesting data state/seed data and E2E testing challenges... I had to Jetpack out of that rabbit hole!

## 5. How did you find not hand-writing code?
Very easy for me, I don’t know Python, and I don’t code with much frequency these days. So I was happy to let the agent do it, and explain it. I found this quite liberating, as it removed my perfectionist OCD tendencies,

## 6. How will this experience influence you going forward?
I really got dialed into where the agents/models are right now. But I have so many questions that I need to explore:
  - How does a scale too much bigger contexts? 
  - How does this work/scale with large legacy code bases? 
  - Should we be creating more specific models for these cases? 
  - General vs. more language pacific models - when should we use one over the other?

**Game Changer**: 
This totally changes my workflow, and my mindset towards developing solutions
I will be confident to build prototypes... over-confident??
More than this, I now feel a natural pull to want to build things, as these tools allow me to jump over my coding/configuration skills gap, which was always a mental hurdle and time-barrier.


